# pts_biosphere2

# ğŸŒ Biosphere 2 Digital Twin AI

**An AI-powered, real-time digital twin simulation of the Biosphere 2 ecosystem**, integrating sensor data, crop health analysis, autonomous terrain navigation, and a local LLM-based decision-making interface.

> ğŸ§  Hackathon Project | XR + AI Ecosystem Intelligence | Real-Time Visualization | LLM-Aided Control

---

## ğŸš€ Project Overview

This project simulates a digital twin of **Biosphere 2**, using real sensor data and reinforcement learning to:

- ğŸŒ± Monitor **crop health** using environmental metrics (COâ‚‚, PAR, Temp, RH)
- ğŸ¤– Navigate a 2D terrain with an **RL-trained agent** avoiding obstacles and reaching crop zones
- ğŸ§  Use **Local LLM Reasoning** to decide when to irrigate, ventilate, or reroute paths based on sensor alerts
- ğŸ–¥ï¸ Provide both a **visual simulation** (via Pygame) and a **chat interface** (via FastAPI + HTML)

---

## ğŸ§© Key Features

| Feature               | Description                                                                 |
|-----------------------|-----------------------------------------------------------------------------|
| ğŸŒ¡ï¸ Sensor Fusion       | Aggregates real-time CSV sensor streams (COâ‚‚, Temp, PAR, RH)                  |
| ğŸ§  LLM Reasoner        | Connects to a local LLM (via [Ollama](https://ollama.com)) for reasoning       |
| ğŸ›°ï¸ Terrain Agent       | RL-trained agent (Q-learning) navigates terrain with crops and obstacles       |
| ğŸ§º Crop Health Engine  | Evaluates crops (Tomatoes, Corn) and color-codes health status                |
| ğŸ’¬ Web Chatbot         | Ask questions to the Digital Twin and get AI-backed recommendations           |
| ğŸ–¼ï¸ Overlay UI          | Real-time simulation with visual feedback (alerts, AI thoughts, health)       |

---

## ğŸ—‚ï¸ Code Structure

â”œâ”€â”€ main.py                # Runs the simulation loop (Pygame + Q-Learning + Sensor + AI)
â”œâ”€â”€ sensor_interface.py    # Loads and streams real Biosphere 2 sensor CSVs
â”œâ”€â”€ crop_health.py         # Scores and colorizes crop health based on environmental factors
â”œâ”€â”€ terrain_agent.py       # RL agent logic and terrain generation
â”œâ”€â”€ control_engine.py      # Applies AI-driven actions (irrigate, ventilate, reroute)
â”œâ”€â”€ llm_reasoner.py        # Interacts with local LLM (Ollama) and parses reasoning
â”œâ”€â”€ twin_overlay.py        # Renders UI overlays in simulation window
â”œâ”€â”€ web_chatbot.py         # FastAPI-powered chatbot for user-AI interaction
â”œâ”€â”€ q_table.pkl            # Q-learning knowledge base (auto-generated)


---

## ğŸ§  AI + RL Architecture

- **Reinforcement Learning (Q-Learning)** trains the agent to reach crops efficiently.
- **Local LLM** (like Mistral via Ollama) interprets sensor alerts and recommends actions.
- **AI actions** are parsed, applied, and reflected live in both the simulation and the web chatbot.

---

## ğŸ–¥ï¸ Getting Started

### ğŸ”§ Prerequisites

- Python 3.9+
- [Ollama](https://ollama.com) installed locally to run LLMs like `mistral`

### ğŸ“¦ Install Dependencies

```bash
pip install pygame fastapi uvicorn pandas

---
ğŸ¤– Pull the LLM Model
bash
Copy
Edit
ollama pull mistral
â–¶ï¸ Run the Simulator (Pygame Visualization)
bash
Copy
Edit
python main.py

---
ğŸ’¬ Launch the Web Chat Interface
bash
Copy
Edit
python web_chatbot.py
Then open your browser and visit: http://127.0.0.1:8080




